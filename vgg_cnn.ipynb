{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "282ut6cGvQjQ",
        "outputId": "e27568a2-79fa-4f71-f686-8567b971b139"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"sonalsingh99314\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"45fbddeeb915a88e4d938ae2fc593b60\" # Provide your key from the json file\n",
        "!kaggle competitions download -c dogs-vs-cats # api copied from kaggle"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test1.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sampleSubmission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wR6eC85vflw",
        "outputId": "887d2b2e-1dcf-4124-a923-52121e700822"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = \"/content/train.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ta4oTukvo7M",
        "outputId": "b32de0fa-ea18-474a-c99c-0afdd48d90d9"
      },
      "source": [
        "data_dir_list = os.listdir('/content/train')\n",
        "#print(data_dir_list)\n",
        "\n",
        "path, dirs, files = next(os.walk(\"/content/train\"))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqoR8rKqvuUo"
      },
      "source": [
        "original_dataset_dir = '/content/train'\n",
        "base_dir = '/content/cats_and_dogs_small'\n",
        "os.mkdir(base_dir) #make base directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdUjNckTvzfE"
      },
      "source": [
        "#Create directory paths\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvGJmlldv3-6"
      },
      "source": [
        "import shutil\n",
        "fnames=['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "  src=os.path.join(original_dataset_dir,fname)\n",
        "  dst=os.path.join(train_cats_dir,fname)\n",
        "  #print(src,dst)\n",
        "  shutil.copyfile(src,dst)\n",
        "fnames=['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
        "for fname in fnames:\n",
        "  src=os.path.join(original_dataset_dir,fname)\n",
        "  dst=os.path.join(validation_cats_dir,fname)\n",
        "  #print(src,dst)\n",
        "  shutil.copyfile(src,dst)  \n",
        "fnames=['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
        "for fname in fnames:\n",
        "  src=os.path.join(original_dataset_dir,fname)\n",
        "  dst=os.path.join(test_cats_dir,fname)\n",
        "  #print(src,dst)\n",
        "  shutil.copyfile(src,dst)  \n",
        "fnames=['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "  src=os.path.join(original_dataset_dir,fname)\n",
        "  dst=os.path.join(train_dogs_dir,fname)\n",
        "  #print(src,dst)\n",
        "  shutil.copyfile(src,dst) \n",
        "fnames=['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
        "for fname in fnames:\n",
        "  src=os.path.join(original_dataset_dir,fname)\n",
        "  dst=os.path.join(validation_dogs_dir,fname)\n",
        "  #print(src,dst)\n",
        "  shutil.copyfile(src,dst)   \n",
        "fnames=['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
        "for fname in fnames:\n",
        "  src=os.path.join(original_dataset_dir,fname)\n",
        "  dst=os.path.join(test_dogs_dir,fname)\n",
        "  #print(src,dst)\n",
        "  shutil.copyfile(src,dst)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG36G05HyipV",
        "outputId": "5fec16a9-ac00-401e-9698-9059c5c75fe6"
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n",
            "total test cat images: 500\n",
            "total test dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR5TnLfEjI23"
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6RTw5E8jJBv",
        "outputId": "a9fe491f-2be7-4e25-893e-9ac106944048"
      },
      "source": [
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory( validation_dir,  batch_size = 20, class_mode = 'binary', target_size = (224, 224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtOWOlqcbd0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e4a7b6-fdde-4fc2-9b37-13daec2f43cf"
      },
      "source": [
        "#VGG-16\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8QaTbW0bs4e"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOx4ENrzb1Nk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a32c8c5-f234-43fb-d723-d0bd5132ce04"
      },
      "source": [
        "from tensorflow.keras import layers \n",
        "import tensorflow as tf \n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(base_model.output)\n",
        "\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.models.Model(base_model.input, x)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90r7H-pQc1VL",
        "outputId": "9bc96bbf-fb16-4879-a298-aae577187755"
      },
      "source": [
        "# fitting the model\n",
        "from tensorflow.keras import Model \n",
        "vgghist = model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 10)\n",
        "model.save('vgghist')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 0.2815 - acc: 0.8795 - val_loss: 0.2022 - val_acc: 0.9200\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 37s 373ms/step - loss: 0.2780 - acc: 0.8840 - val_loss: 0.2043 - val_acc: 0.9210\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 37s 374ms/step - loss: 0.2756 - acc: 0.8920 - val_loss: 0.2046 - val_acc: 0.9210\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 0.2661 - acc: 0.8825 - val_loss: 0.1954 - val_acc: 0.9270\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 37s 372ms/step - loss: 0.2854 - acc: 0.8745 - val_loss: 0.2411 - val_acc: 0.9070\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 37s 368ms/step - loss: 0.2815 - acc: 0.8800 - val_loss: 0.2474 - val_acc: 0.9010\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 37s 372ms/step - loss: 0.2716 - acc: 0.8870 - val_loss: 0.1902 - val_acc: 0.9240\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 38s 377ms/step - loss: 0.2894 - acc: 0.8860 - val_loss: 0.2065 - val_acc: 0.9260\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 0.2634 - acc: 0.8990 - val_loss: 0.2746 - val_acc: 0.8990\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 38s 379ms/step - loss: 0.2806 - acc: 0.8865 - val_loss: 0.2796 - val_acc: 0.8920\n",
            "INFO:tensorflow:Assets written to: vgghist/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG8IbaHEqpq_",
        "outputId": "8ec1cb0b-8aa2-45f6-ea80-dfa215fd22a5"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        " \n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(224, 224))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 224, 224, 3)\n",
        "\t# center pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img - [123.68, 116.779, 103.939]\n",
        "\treturn img\n",
        " \n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('/content/cats_and_dogs_small/test/dogs/dog.1509.jpg')\n",
        "\t# load model\n",
        "\tmodel = load_model('vgghist')\n",
        "\t# predict the class\n",
        "\tresult = model.predict(img)\n",
        "\tprint(result[0])\n",
        " \n",
        "# entry point, run the example\n",
        "run_example()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYE9CMT4uZwI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}